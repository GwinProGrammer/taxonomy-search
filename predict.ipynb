{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "77f180ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Load Model and Tokenizer\n",
    "model_path = \"models/model_20250411_122546\"\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "# 2. Load Label Mappings\n",
    "with open(f\"{model_path}/label_mappings.json\", \"r\") as f:\n",
    "    mappings = json.load(f)\n",
    "    id2label = {int(k): v for k, v in mappings[\"id2label\"].items()}\n",
    "\n",
    "# 3. Enhanced Prediction Function (Returns Full Distribution)\n",
    "def predict_with_distribution(text, top_k=3):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1).numpy()[0]\n",
    "    \n",
    "    # Get all labels and their probabilities\n",
    "    predictions = []\n",
    "    for label_id, prob in enumerate(probs):\n",
    "        predictions.append({\n",
    "            \"label\": id2label[label_id],\n",
    "            \"score\": float(prob)  # Convert numpy float to Python float\n",
    "        })\n",
    "    \n",
    "    # Sort by probability (descending)\n",
    "    predictions.sort(key=lambda x: x[\"score\"], reverse=True)\n",
    "    \n",
    "    return predictions[:top_k]  # Return top K predictions\n",
    "\n",
    "# 4. Process Files with Distribution\n",
    "test_dir = Path(\"/Users/gwin/Documents/Post Undergrad Work/Tax Search/test_data/test_clean\")\n",
    "results = []\n",
    "\n",
    "for txt_file in test_dir.glob(\"*.txt\"):\n",
    "    text = txt_file.read_text(encoding=\"utf-8\").strip()\n",
    "    if not text:\n",
    "        continue\n",
    "    \n",
    "    predictions = predict_with_distribution(text)\n",
    "    \n",
    "    # Format for readable output\n",
    "    dist_str = \" | \".join([f\"{p['label']}: {p['score']:.1%}\" for p in predictions])\n",
    "    top_pred = predictions[0]\n",
    "    \n",
    "    results.append({\n",
    "        \"file\": txt_file.name,\n",
    "        \"top_label\": top_pred[\"label\"],\n",
    "        \"top_score\": top_pred[\"score\"],\n",
    "        \"distribution\": dist_str,\n",
    "        \"full_distribution\": predictions  # Keep raw data\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16c821f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 file            top_label  top_score  \\\n",
      "0  2022_DPC_Year_in_Review_Report.txt  defense|procurement    0.28893   \n",
      "\n",
      "                                        distribution  \n",
      "0  defense|procurement: 28.9% | defense|cybersecu...  \n"
     ]
    }
   ],
   "source": [
    "# 5. Save Results\n",
    "df = pd.DataFrame(results)\n",
    "print(df[[\"file\", \"top_label\", \"top_score\", \"distribution\"]])  # Preview\n",
    "df.to_csv(\"predictions_with_distribution.csv\", index=False)\n",
    "df.to_json(\"predictions_full.json\", orient=\"records\", indent=2)  # Full data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
