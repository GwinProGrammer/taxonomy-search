{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 49\u001b[0m\n\u001b[1;32m     42\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe Pentagon announced new defense contracts worth $2 billion\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMedicaid expansion approved for low-income families\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe education department issued new grant guidelines\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     46\u001b[0m ]\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m test_texts:\n\u001b[0;32m---> 49\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtext[:\u001b[38;5;241m60\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPrediction: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (Confidence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2%\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[6], line 36\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     32\u001b[0m pred_id \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     33\u001b[0m confidence \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m][pred_id]\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[0;32m---> 36\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[43mid2label\u001b[49m\u001b[43m[\u001b[49m\u001b[43mpred_id\u001b[49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconfidence\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(confidence, \u001b[38;5;241m4\u001b[39m),\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_output\u001b[39m\u001b[38;5;124m\"\u001b[39m: logits\u001b[38;5;241m.\u001b[39mtolist()[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     39\u001b[0m }\n",
      "\u001b[0;31mKeyError\u001b[0m: 9"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "\n",
    "# 1. Load your saved model and tokenizer\n",
    "model_path = \"/Users/gwin/Documents/Post Undergrad Work/Tax Search/my_finetuned_model\"  # Path where you saved your model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "\n",
    "# 2. Prepare your label mappings (ensure these match your training)\n",
    "id2label = {\n",
    "    0: \"defense|procurement\", \n",
    "    1: \"healthcare|medicaid\",\n",
    "    # ... add all your other labels\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "# 3. Create a prediction function\n",
    "def predict(text):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(text, \n",
    "                      return_tensors=\"pt\", \n",
    "                      truncation=True, \n",
    "                      max_length=512,\n",
    "                      padding=True)\n",
    "    \n",
    "    # Get predictions\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Process output\n",
    "    logits = outputs.logits\n",
    "    pred_id = torch.argmax(logits, dim=1).item()\n",
    "    confidence = torch.softmax(logits, dim=1)[0][pred_id].item()\n",
    "    \n",
    "    return {\n",
    "        \"label\": id2label[pred_id],\n",
    "        \"confidence\": round(confidence, 4),\n",
    "        \"raw_output\": logits.tolist()[0]\n",
    "    }\n",
    "\n",
    "# 4. Test the model\n",
    "test_texts = [\n",
    "    \"The Pentagon announced new defense contracts worth $2 billion\",\n",
    "    \"Medicaid expansion approved for low-income families\",\n",
    "    \"The education department issued new grant guidelines\"\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = predict(text)\n",
    "    print(f\"Text: {text[:60]}...\")\n",
    "    print(f\"Prediction: {result['label']} (Confidence: {result['confidence']:.2%})\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.23.5\n",
      "PyTorch version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(\"NumPy version:\", np.__version__)  # Should show 1.23.5 or similar 1.x version\n",
    "print(\"PyTorch version:\", torch.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
